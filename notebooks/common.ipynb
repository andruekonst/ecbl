{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sympy import Symbol, Eq, Implies, Equivalent\n",
    "import sympy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import reduce, partial\n",
    "from operator import mul\n",
    "from collections import defaultdict\n",
    "from typing import Optional, Mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels(make_labels_fn, main_target: str = 'y_0'):\n",
    "    shape = (40, 40)\n",
    "    x_grid = np.stack(\n",
    "        np.meshgrid(\n",
    "            *[\n",
    "                np.linspace(0, 1, s)\n",
    "                for s in shape\n",
    "            ],\n",
    "            indexing='ij',\n",
    "        ),\n",
    "        axis=-1\n",
    "    ).reshape((reduce(mul, shape, 1), len(shape))).astype(np.float32)\n",
    "\n",
    "    all_preds = make_labels_fn(x_grid)\n",
    "    preds = all_preds[main_target]\n",
    "    titles = {\n",
    "        main_target: f'$y = {main_target}$',\n",
    "    }\n",
    "    # notation used in paper\n",
    "    # titles.update({f'y_{t}': '$c^{(' + str(t) + ')}$' for t in range(1, 4)})\n",
    "    titles.update({f'y_{t}': f'$y_{t}$' for t in range(1, 4)})\n",
    "\n",
    "    cmap = plt.colormaps['rainbow'].resampled(3)\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(6, 6), layout='compressed')\n",
    "    for i, k in enumerate(all_preds.keys()):\n",
    "        a = ax.ravel()[i]\n",
    "        im = a.pcolormesh(\n",
    "            x_grid[:, 0].reshape(shape),\n",
    "            x_grid[:, 1].reshape(shape),\n",
    "            all_preds[k].reshape(shape),\n",
    "            cmap=cmap,\n",
    "            vmin=0.0, vmax=1.0,\n",
    "            # levels=np.array([0, 1, 2]),  # np.linspace(0.0, 1.0, 11)\n",
    "        )\n",
    "        im.set_clim((0, 2))\n",
    "        a.set_xticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "        a.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "        # a.axis('equal')\n",
    "        a.set_aspect(1)\n",
    "        a.set_title(titles[k])\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # fig.subplots_adjust(right=0.8)\n",
    "    # cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    # fig.colorbar(im, cax=cbar_ax)\n",
    "    bar = fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.5, ticks=np.array([0, 1, 2]))\n",
    "    bar.ax.set_ylabel('class', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, device: str = 'cpu', input_dtype=torch.float, shape: tuple = (40, 40)):\n",
    "    x_grid = np.stack(\n",
    "        np.meshgrid(\n",
    "            *[\n",
    "                np.linspace(0, 1, s)\n",
    "                for s in shape\n",
    "            ],\n",
    "            indexing='ij',\n",
    "        ),\n",
    "        axis=-1\n",
    "    ).reshape((reduce(mul, shape, 1), len(shape))).astype(np.float32)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_preds = {\n",
    "            k: v.cpu()\n",
    "            for k, v in model(torch.tensor(x_grid).to(input_dtype).to(device)).items()\n",
    "        }\n",
    "        preds = all_preds['y_0'].numpy()\n",
    "    titles = {\n",
    "        'y_0': '$\\Pr(y = 2)$',\n",
    "    }\n",
    "    titles.update({f'y_{t}': '$\\Pr(c^{(' + str(t) + ')} = 2)$' for t in range(1, 4)})\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(6, 6), layout='compressed')\n",
    "    for i, k in enumerate(all_preds.keys()):\n",
    "        a = ax.ravel()[i]\n",
    "        im = a.contourf(\n",
    "            x_grid[:, 0].reshape(shape),\n",
    "            x_grid[:, 1].reshape(shape),\n",
    "            np.clip(all_preds[k].numpy()[:, 1].reshape(shape), 0.0, 1.0),\n",
    "            cmap='plasma',\n",
    "            vmin=0.0, vmax=1.0,\n",
    "            levels=np.linspace(0.0, 1.0, 11)\n",
    "        )\n",
    "        im.set_clim((0.0, 1.0))\n",
    "        a.set_xticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "        a.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "        # a.axis('equal')\n",
    "        a.set_aspect(1)\n",
    "        a.set_title(titles[k])\n",
    "\n",
    "    bar = fig.colorbar(im, ax=ax.ravel().tolist(), extend='neighter', shrink=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedTensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, named_tensors: Mapping[str, torch.Tensor]):\n",
    "        self.named_tensors = named_tensors\n",
    "\n",
    "    def __getitem__(self, i) -> Mapping[str, torch.Tensor]:\n",
    "        return {\n",
    "            k: v[i]\n",
    "            for k, v in self.named_tensors.items()\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        lengths = [len(v) for v in self.named_tensors.values()]\n",
    "        assert reduce(lambda a, b: b if a is None or a == b else -1, lengths, None) != -1, \\\n",
    "            f\"All tensors must have the same length! Got: {lengths}\"\n",
    "        return lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model_parameters(nn, seed: Optional[int] = None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    def _visitor(layer):\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            layer.reset_parameters()\n",
    "        return\n",
    "\n",
    "    nn.apply(_visitor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_loader(dataset, device: str, batch_size: int):\n",
    "    device_params = dict()\n",
    "    if device != 'cpu':\n",
    "        device_params = {'pin_memory': True, 'pin_memory_device': device}\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        **device_params\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def train_on_dataset(model, dataset,\n",
    "                     n_epochs: int = 100,\n",
    "                     device: str = 'cpu',\n",
    "                     optim_factory = None,\n",
    "                     seed: int = 12345,\n",
    "                     batch_size: int = 16,\n",
    "                     input_key: str = 'X',\n",
    "                     input_dtype=torch.float,\n",
    "                     epoch_callback=None):\n",
    "    \"\"\"Train the model on the dataset.\n",
    "\n",
    "    Args:\n",
    "        model: Model.\n",
    "        dataset: Train dataset, consisting of dictionaries (key -> data tensor).\n",
    "        device: Device, 'cpu' or 'cuda:n', e.g. 'cuda:0'.\n",
    "        optim_factory: Optimizator factory, getting model parameters and returning optimizator.\n",
    "\n",
    "                For example, `lambda params: torch.optim.SGD(params, lr=1.e-2)`.\n",
    "\n",
    "        seed: Random seed.\n",
    "        batch_size: Batch size.\n",
    "        input_key: Name of the input tensor in the dataset. By default is 'X'.\n",
    "\n",
    "    \"\"\"\n",
    "    EPS = 1.e-12\n",
    "    reset_model_parameters(model, seed=seed)\n",
    "    model.to(device)\n",
    "\n",
    "    if optim_factory is None:\n",
    "        optim_factory = partial(torch.optim.AdamW, lr=1.e-4)\n",
    "    optim = optim_factory(model.parameters())\n",
    "\n",
    "    loader = prepare_train_loader(dataset, device, batch_size=batch_size)\n",
    "\n",
    "    clf_loss_fn = torch.nn.NLLLoss()  # predictions are probabilities, not logits (!)\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        batch_losses = []\n",
    "        for data in loader:\n",
    "            data_device = {\n",
    "                k: v.to(device)\n",
    "                for k, v in data.items()\n",
    "                if k != input_key\n",
    "            }\n",
    "            batch_x = data[input_key].to(input_dtype).to(device)\n",
    "            concept_probas = model(batch_x)\n",
    "\n",
    "            loss = 0.0\n",
    "            for concept_name, preds in concept_probas.items():\n",
    "                if concept_name in data:\n",
    "                    loss = loss + clf_loss_fn(\n",
    "                        torch.log(torch.clamp_min(preds, EPS)),\n",
    "                        data_device[concept_name]\n",
    "                    )\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        history['loss_train'].append(np.mean(batch_losses))\n",
    "        if epoch_callback is not None:\n",
    "            epoch_callback(model)\n",
    "    model.eval()\n",
    "\n",
    "    return history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecbl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
